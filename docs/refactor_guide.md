# YouTube å­—å¹•å·¥å…· - ä»£ç ç²¾ç®€é‡æ„æ‰§è¡Œæ–‡æ¡£

> æœ¬æ–‡æ¡£æŒ‡å¯¼å¦‚ä½•ç²¾ç®€é¡¹ç›®ä¸­çš„å†—ä½™ä»£ç ï¼Œé¢„è®¡å‡å°‘ **1,000-1,300 è¡Œ**ä»£ç ã€‚

---

## ğŸ“‹ é‡æ„æ¦‚è§ˆ

| ä»»åŠ¡ | ç²¾ç®€é‡ | ä¼˜å…ˆçº§ | é£é™© |
|------|-------|-------|------|
| ä»»åŠ¡1: ai_providers åŸºç±»é‡æ„ | ~660è¡Œ | ğŸ”´ é«˜ | ä½ |
| ä»»åŠ¡2: language_config_section UIç»„ä»¶ | ~300-400è¡Œ | ğŸ”´ é«˜ | ä½ |
| ä»»åŠ¡3: language_strategy ç»Ÿä¸€ | ~200-300è¡Œ | ğŸŸ¡ ä¸­ | ä¸­ |
| **åˆè®¡** | **~1,160-1,360è¡Œ** | | |

---

## ä»»åŠ¡1: ai_providers åŸºç±»é‡æ„

### 1.1 é—®é¢˜åˆ†æ

å½“å‰ `core/ai_providers/` ä¸‹çš„æ¯ä¸ª provider æ–‡ä»¶éƒ½é‡å¤å®ç°äº†ä»¥ä¸‹é€»è¾‘ï¼š

| é‡å¤ä»£ç å— | è¡Œæ•° | å‡ºç°æ¬¡æ•° |
|-----------|------|---------|
| API Key åŠ è½½é€»è¾‘ | ~15è¡Œ | 5æ¬¡ |
| 4ä¸ªæ ‡å‡†å±æ€§å®šä¹‰ | ~20è¡Œ | 5æ¬¡ |
| Semaphore å¹¶å‘æ§åˆ¶ | ~5è¡Œ | 5æ¬¡ |
| é‡è¯•å¾ªç¯æ¡†æ¶ | ~50è¡Œ | 5æ¬¡ |
| é”™è¯¯åˆ†ç±»å¤„ç† | ~40è¡Œ | 5æ¬¡ |
| ä¾èµ–æ£€æŸ¥æ–¹æ³• | ~8è¡Œ | 5æ¬¡ |

### 1.2 ç›®æ ‡æ¶æ„

```
æ”¹é€ å‰:
â”œâ”€â”€ base.py              â†’ 130è¡Œ (åªæœ‰é…ç½®æ•°æ®)
â”œâ”€â”€ anthropic.py         â†’ 200è¡Œ (å®Œæ•´å®ç°)
â”œâ”€â”€ openai_compatible.py â†’ 270è¡Œ (å®Œæ•´å®ç°)
â”œâ”€â”€ gemini.py            â†’ 210è¡Œ (å®Œæ•´å®ç°)
â”œâ”€â”€ local_model.py       â†’ ~200è¡Œ (å®Œæ•´å®ç°)
â”œâ”€â”€ google_translate.py  â†’ ~150è¡Œ (å®Œæ•´å®ç°)
æ€»è®¡: ~1,160è¡Œ

æ”¹é€ å:
â”œâ”€â”€ base.py              â†’ 280è¡Œ (é…ç½® + åŸºç±»)
â”œâ”€â”€ anthropic.py         â†’ 45è¡Œ (åªæœ‰å·®å¼‚éƒ¨åˆ†)
â”œâ”€â”€ openai_compatible.py â†’ 50è¡Œ (åªæœ‰å·®å¼‚éƒ¨åˆ†)
â”œâ”€â”€ gemini.py            â†’ 55è¡Œ (åªæœ‰å·®å¼‚éƒ¨åˆ†)
â”œâ”€â”€ local_model.py       â†’ 60è¡Œ (åªæœ‰å·®å¼‚éƒ¨åˆ†)
â”œâ”€â”€ google_translate.py  â†’ 50è¡Œ (åªæœ‰å·®å¼‚éƒ¨åˆ†)
æ€»è®¡: ~540è¡Œ
```

### 1.3 æ–°çš„ base.py è®¾è®¡

```python
"""
AI ä¾›åº”å•†åŸºç±»å’Œèƒ½åŠ›é…ç½®
"""

import threading
import time
from abc import ABC, abstractmethod
from typing import Optional, Sequence, List, Dict, Type
from dataclasses import dataclass

from config.manager import AIConfig
from core.llm_client import LLMResult, LLMUsage, LLMException, LLMErrorType, load_api_key
from core.logger import get_logger, translate_exception

logger = get_logger()


@dataclass
class ProviderCapabilities:
    """ä¾›åº”å•†èƒ½åŠ›é…ç½®"""
    supports_vision: bool = False
    supports_streaming: bool = True
    supports_tools: bool = False
    supports_json_mode: bool = False
    default_timeout: int = 60
    max_tokens: int = 4096
    context_window: int = 8000


# ä¿ç•™ç°æœ‰çš„ PROVIDER_CAPABILITIES å­—å…¸...
PROVIDER_CAPABILITIES: Dict[str, ProviderCapabilities] = {
    # ... ä¿æŒç°æœ‰é…ç½®ä¸å˜
}


def get_capabilities(provider: str) -> ProviderCapabilities:
    """è·å–ä¾›åº”å•†èƒ½åŠ›é…ç½®"""
    return PROVIDER_CAPABILITIES.get(provider.lower(), ProviderCapabilities())


class BaseLLMClient(ABC):
    """LLM å®¢æˆ·ç«¯åŸºç±»
    
    å­ç±»åªéœ€å®ç°:
    - provider_name: ä¾›åº”å•†åç§°
    - key_aliases: API Key çš„å¯èƒ½åç§°åˆ—è¡¨
    - required_package: éœ€è¦çš„ Python åŒ…å
    - _do_request(): å®é™…çš„ API è°ƒç”¨
    - _map_exception(): å¼‚å¸¸æ˜ å°„ (å¯é€‰ï¼Œæœ‰é»˜è®¤å®ç°)
    """
    
    # ========== å­ç±»å¿…é¡»å®šä¹‰çš„ç±»å±æ€§ ==========
    provider_name: str = ""  # ä¾‹å¦‚ "anthropic", "openai"
    key_aliases: List[str] = []  # ä¾‹å¦‚ ["anthropic", "claude"]
    required_package: str = ""  # ä¾‹å¦‚ "anthropic"
    
    # ========== å­ç±»å¯é€‰è¦†ç›–çš„ç±»å±æ€§ ==========
    default_max_input_tokens: int = 128000
    default_max_output_tokens: int = 4096
    
    def __init__(self, ai_config: AIConfig):
        """åˆå§‹åŒ–å®¢æˆ·ç«¯ (é€šç”¨é€»è¾‘ï¼Œå­ç±»ä¸éœ€è¦é‡å†™)"""
        self.ai_config = ai_config
        
        # 1. åŠ è½½ API Key (é€šç”¨)
        self.api_key = self._load_api_key()
        
        # 2. æ£€æŸ¥ä¾èµ– (é€šç”¨)
        self._check_dependencies()
        
        # 3. åˆå§‹åŒ–èƒ½åŠ›å±æ€§ (é€šç”¨)
        self._supports_vision = self._check_vision_support(ai_config.model)
        self._max_input_tokens = self.default_max_input_tokens
        self._max_output_tokens = self.default_max_output_tokens
        self._max_concurrency = ai_config.max_concurrency
        
        # 4. åˆ›å»ºå¹¶å‘æ§åˆ¶ Semaphore (é€šç”¨)
        self._sem = threading.Semaphore(self._max_concurrency)
    
    # ========== é€šç”¨å±æ€§ (å­ç±»ä¸éœ€è¦é‡å†™) ==========
    
    @property
    def supports_vision(self) -> bool:
        return self._supports_vision
    
    @property
    def max_input_tokens(self) -> int:
        return self._max_input_tokens
    
    @property
    def max_output_tokens(self) -> int:
        return self._max_output_tokens
    
    @property
    def max_concurrency(self) -> int:
        return self._max_concurrency
    
    # ========== é€šç”¨æ–¹æ³• (å­ç±»ä¸éœ€è¦é‡å†™) ==========
    
    def _load_api_key(self) -> str:
        """åŠ è½½ API Key (é€šç”¨é€»è¾‘)"""
        api_key_config = ""
        for key in self.key_aliases:
            config_val = self.ai_config.api_keys.get(key)
            if config_val:
                api_key_config = config_val
                loaded_key = load_api_key(config_val)
                if loaded_key:
                    return loaded_key
        
        raise LLMException(
            f"exception.ai_api_key_not_found:provider={self.provider_name.capitalize()},config={api_key_config}",
            LLMErrorType.AUTH,
        )
    
    def _check_dependencies(self) -> None:
        """æ£€æŸ¥ä¾èµ–åº“ (é€šç”¨é€»è¾‘)"""
        if not self.required_package:
            return
        try:
            __import__(self.required_package)
        except ImportError:
            raise LLMException(
                translate_exception("exception.ai_dependency_missing", library=self.required_package),
                LLMErrorType.UNKNOWN,
            )
    
    def generate(
        self,
        prompt: str,
        *,
        system: Optional[str] = None,
        max_tokens: Optional[int] = None,
        temperature: Optional[float] = None,
        stop: Optional[Sequence[str]] = None,
    ) -> LLMResult:
        """ç”Ÿæˆå“åº” (é€šç”¨é‡è¯•é€»è¾‘)"""
        start_time = time.time()
        last_error = None
        
        for attempt in range(self.ai_config.max_retries + 1):
            try:
                # ä½¿ç”¨ Semaphore è¿›è¡Œå¹¶å‘é™æµ
                with self._sem:
                    result = self._do_request(
                        prompt=prompt,
                        system=system,
                        max_tokens=min(
                            max_tokens or self.max_output_tokens,
                            self.max_output_tokens,
                        ),
                        temperature=temperature or 0.3,
                        stop=stop,
                    )
                
                # è®°å½•æˆåŠŸæ—¥å¿—
                elapsed = time.time() - start_time
                logger.debug(
                    translate_exception(
                        "log.ai_call_success_detail",
                        provider=self.provider_name.capitalize(),
                        model=self.ai_config.model,
                        elapsed=f"{elapsed:.2f}",
                        tokens=result.usage.total_tokens if result.usage else "N/A",
                    )
                )
                return result
                
            except Exception as e:
                # æ˜ å°„å¼‚å¸¸
                error_type, should_retry = self._map_exception(e)
                last_error = LLMException(str(e), error_type)
                
                # åˆ¤æ–­æ˜¯å¦é‡è¯•
                if should_retry and attempt < self.ai_config.max_retries:
                    wait_time = 2 ** attempt
                    logger.warning_i18n("log.ai_retry_error", wait_time=wait_time)
                    time.sleep(wait_time)
                    continue
                
                raise last_error
        
        if last_error:
            raise last_error
    
    # ========== å­ç±»å¯é€‰è¦†ç›–çš„æ–¹æ³• ==========
    
    def _check_vision_support(self, model: str) -> bool:
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æŒè§†è§‰ (å­ç±»å¯è¦†ç›–)"""
        return False
    
    def _map_exception(self, e: Exception) -> tuple[LLMErrorType, bool]:
        """æ˜ å°„å¼‚å¸¸ç±»å‹ (å­ç±»å¯è¦†ç›–)
        
        Returns:
            (é”™è¯¯ç±»å‹, æ˜¯å¦åº”è¯¥é‡è¯•)
        """
        error_msg = str(e).lower()
        
        if "rate limit" in error_msg or "quota" in error_msg:
            return LLMErrorType.RATE_LIMIT, True
        elif "auth" in error_msg or "api key" in error_msg or "permission" in error_msg:
            return LLMErrorType.AUTH, False
        elif "network" in error_msg or "connection" in error_msg or "timeout" in error_msg:
            return LLMErrorType.NETWORK, True
        elif "safety" in error_msg or "content" in error_msg or "blocked" in error_msg:
            return LLMErrorType.CONTENT, False
        else:
            return LLMErrorType.UNKNOWN, False
    
    # ========== å­ç±»å¿…é¡»å®ç°çš„æ–¹æ³• ==========
    
    @abstractmethod
    def _do_request(
        self,
        prompt: str,
        system: Optional[str],
        max_tokens: int,
        temperature: float,
        stop: Optional[Sequence[str]],
    ) -> LLMResult:
        """æ‰§è¡Œå®é™…çš„ API è¯·æ±‚ (å­ç±»å¿…é¡»å®ç°)
        
        æ³¨æ„: ä¸éœ€è¦å¤„ç†é‡è¯•ã€å¹¶å‘æ§åˆ¶ã€æ—¥å¿—ï¼Œè¿™äº›ç”±åŸºç±»å¤„ç†
        """
        pass
```

### 1.4 æ–°çš„ anthropic.py è®¾è®¡ (ç¤ºä¾‹)

```python
"""
Anthropic Claude å®¢æˆ·ç«¯å®ç°
"""

from typing import Optional, Sequence

from core.llm_client import LLMResult, LLMUsage, LLMErrorType
from .base import BaseLLMClient


class AnthropicClient(BaseLLMClient):
    """Anthropic LLM å®¢æˆ·ç«¯"""
    
    # ç±»å±æ€§å®šä¹‰
    provider_name = "anthropic"
    key_aliases = ["anthropic", "claude"]
    required_package = "anthropic"
    default_max_input_tokens = 200000
    default_max_output_tokens = 8192
    
    def _check_vision_support(self, model: str) -> bool:
        """Claude 3.x ç³»åˆ—æ”¯æŒè§†è§‰"""
        model_lower = model.lower()
        return any(x in model_lower for x in ["opus", "sonnet", "haiku"])
    
    def _do_request(
        self,
        prompt: str,
        system: Optional[str],
        max_tokens: int,
        temperature: float,
        stop: Optional[Sequence[str]],
    ) -> LLMResult:
        """è°ƒç”¨ Anthropic API"""
        import anthropic
        
        client = anthropic.Anthropic(
            api_key=self.api_key,
            base_url=self.ai_config.base_url,
            timeout=self.ai_config.timeout_seconds,
        )
        
        response = client.messages.create(
            model=self.ai_config.model,
            max_tokens=max_tokens,
            system=system,
            messages=[{"role": "user", "content": prompt}],
            temperature=temperature,
        )
        
        # è§£æå“åº”
        text = response.content[0].text if response.content else ""
        usage = None
        if response.usage:
            usage = LLMUsage(
                prompt_tokens=response.usage.input_tokens,
                completion_tokens=response.usage.output_tokens,
                total_tokens=response.usage.input_tokens + response.usage.output_tokens,
            )
        
        return LLMResult(
            text=text,
            usage=usage,
            provider=self.provider_name,
            model=self.ai_config.model,
        )
    
    def _map_exception(self, e: Exception) -> tuple[LLMErrorType, bool]:
        """æ˜ å°„ Anthropic ç‰¹å®šå¼‚å¸¸"""
        from anthropic import (
            RateLimitError,
            AuthenticationError,
            APIConnectionError,
            APIError,
        )
        
        if isinstance(e, RateLimitError):
            return LLMErrorType.RATE_LIMIT, True
        elif isinstance(e, AuthenticationError):
            return LLMErrorType.AUTH, False
        elif isinstance(e, APIConnectionError):
            return LLMErrorType.NETWORK, True
        elif isinstance(e, APIError):
            error_msg = str(e).lower()
            if any(kw in error_msg for kw in ["content", "safety", "policy"]):
                return LLMErrorType.CONTENT, False
            return LLMErrorType.UNKNOWN, True
        else:
            return super()._map_exception(e)
```

### 1.5 å…¶ä»– provider çš„æ”¹é€ æ¨¡å¼

#### openai_compatible.py (~50è¡Œ)

```python
class OpenAICompatibleClient(BaseLLMClient):
    provider_name = "openai"  # ä¼šè¢« ai_config.provider è¦†ç›–
    key_aliases = ["openai", "openai_compatible"]  # å­ç±»æ„é€ æ—¶åŠ¨æ€æ·»åŠ 
    required_package = "openai"
    
    def __init__(self, ai_config: AIConfig):
        # åŠ¨æ€è®¾ç½® provider_name å’Œ key_aliases
        self.provider_name = ai_config.provider
        self.key_aliases = [ai_config.provider, "openai", "openai_compatible"]
        super().__init__(ai_config)
    
    def _check_vision_support(self, model: str) -> bool:
        model_lower = model.lower()
        return "vision" in model_lower or "gpt-4o" in model_lower
    
    def _do_request(self, prompt, system, max_tokens, temperature, stop) -> LLMResult:
        import openai
        client = openai.OpenAI(
            api_key=self.api_key,
            base_url=self.ai_config.base_url or "https://api.openai.com/v1",
            timeout=self.ai_config.timeout_seconds,
        )
        messages = []
        if system:
            messages.append({"role": "system", "content": system})
        messages.append({"role": "user", "content": prompt})
        
        response = client.chat.completions.create(
            model=self.ai_config.model,
            messages=messages,
            max_tokens=max_tokens,
            temperature=temperature,
            stop=stop,
        )
        # ... è§£æå“åº” (ç±»ä¼¼ anthropic)
```

#### gemini.py (~55è¡Œ)

```python
class GeminiClient(BaseLLMClient):
    provider_name = "gemini"
    key_aliases = ["gemini", "google"]
    required_package = "google.generativeai"
    default_max_input_tokens = 128000
    default_max_output_tokens = 8192
    
    def _check_vision_support(self, model: str) -> bool:
        return True  # Gemini å…¨ç³»åˆ—æ”¯æŒè§†è§‰
    
    def _do_request(self, prompt, system, max_tokens, temperature, stop) -> LLMResult:
        import google.generativeai as genai
        genai.configure(api_key=self.api_key)
        model = genai.GenerativeModel(self.ai_config.model)
        
        full_prompt = f"{system}\n\n{prompt}" if system else prompt
        response = model.generate_content(
            full_prompt,
            generation_config={
                "max_output_tokens": max_tokens,
                "temperature": temperature,
                "stop_sequences": stop if stop else None,
            },
        )
        
        return LLMResult(
            text=response.text if hasattr(response, "text") else "",
            usage=None,  # Gemini ä¸ç›´æ¥æä¾› token ç»Ÿè®¡
            provider=self.provider_name,
            model=self.ai_config.model,
        )
```

### 1.6 æ‰§è¡Œæ­¥éª¤

1. **å¤‡ä»½åŸæ–‡ä»¶**
   ```bash
   cp -r core/ai_providers core/ai_providers_backup
   ```

2. **ä¿®æ”¹ base.py**
   - ä¿ç•™ç°æœ‰çš„ `ProviderCapabilities` å’Œ `PROVIDER_CAPABILITIES`
   - æ·»åŠ  `BaseLLMClient` æŠ½è±¡åŸºç±»

3. **é€ä¸ªæ”¹é€  provider**ï¼ˆå»ºè®®é¡ºåºï¼‰
   - `anthropic.py` (æœ€ç®€å•ï¼Œå…ˆæ”¹è¿™ä¸ªéªŒè¯åŸºç±»è®¾è®¡)
   - `openai_compatible.py`
   - `gemini.py`
   - `local_model.py`
   - `google_translate.py`

4. **æ¯æ”¹ä¸€ä¸ªï¼Œè¿è¡Œæµ‹è¯•**
   ```bash
   python -c "from core.ai_providers import AnthropicClient; print('OK')"
   ```

5. **å…¨éƒ¨æ”¹å®Œåï¼Œè¿è¡Œé›†æˆæµ‹è¯•**

---

## ä»»åŠ¡2: language_config_section UI ç»„ä»¶æŠ½å–

### 2.1 é—®é¢˜åˆ†æ

`ui/pages/url_list_page.py` å’Œ `ui/pages/channel_page.py` ä¸­æœ‰å¤§é‡é‡å¤çš„è¯­è¨€é…ç½® UI ä»£ç ï¼š
- æºè¯­è¨€é€‰æ‹©
- ç›®æ ‡è¯­è¨€é€‰æ‹©
- åŒè¯­æ¨¡å¼å¼€å…³
- ç¿»è¯‘ç­–ç•¥é€‰æ‹©

### 2.2 ç›®æ ‡æ¶æ„

```
æ”¹é€ å‰:
â”œâ”€â”€ url_list_page.py     â†’ ~850è¡Œ (åŒ…å«è¯­è¨€é…ç½® UI)
â”œâ”€â”€ channel_page.py      â†’ ~700è¡Œ (åŒ…å«è¯­è¨€é…ç½® UIï¼Œé‡å¤!)
æ€»è®¡: ~1,550è¡Œ

æ”¹é€ å:
â”œâ”€â”€ components/
â”‚   â””â”€â”€ language_config_section.py â†’ ~200è¡Œ (æå–çš„å…¬å…±ç»„ä»¶)
â”œâ”€â”€ url_list_page.py     â†’ ~650è¡Œ (ä½¿ç”¨ç»„ä»¶)
â”œâ”€â”€ channel_page.py      â†’ ~500è¡Œ (ä½¿ç”¨ç»„ä»¶)
æ€»è®¡: ~1,350è¡Œ
```

### 2.3 æ–°ç»„ä»¶è®¾è®¡

```python
# ui/components/language_config_section.py

"""
è¯­è¨€é…ç½®ç»„ä»¶
å¯å¤ç”¨äº url_list_page å’Œ channel_page
"""

import customtkinter as ctk
from typing import Callable, Optional, List
from ui.i18n import get_text


class LanguageConfigSection(ctk.CTkFrame):
    """è¯­è¨€é…ç½®åŒºåŸŸç»„ä»¶
    
    åŒ…å«:
    - æºè¯­è¨€é€‰æ‹©
    - ç›®æ ‡è¯­è¨€é€‰æ‹© (å¤šé€‰)
    - æ‘˜è¦è¯­è¨€é€‰æ‹©
    - åŒè¯­æ¨¡å¼å¼€å…³
    - ç¿»è¯‘ç­–ç•¥é€‰æ‹©
    """
    
    def __init__(
        self,
        parent,
        on_config_changed: Optional[Callable] = None,
        **kwargs
    ):
        super().__init__(parent, **kwargs)
        self.on_config_changed = on_config_changed
        self._create_widgets()
    
    def _create_widgets(self):
        """åˆ›å»ºæ‰€æœ‰è¯­è¨€é…ç½®æ§ä»¶"""
        # æºè¯­è¨€
        self.source_lang_label = ctk.CTkLabel(
            self, text=get_text("source_language")
        )
        self.source_lang_label.grid(row=0, column=0, sticky="w", padx=5, pady=5)
        
        self.source_lang_combo = ctk.CTkComboBox(
            self,
            values=self._get_language_options(),
            command=self._on_change
        )
        self.source_lang_combo.grid(row=0, column=1, sticky="ew", padx=5, pady=5)
        
        # ç›®æ ‡è¯­è¨€ (å¤šé€‰)
        self.target_lang_label = ctk.CTkLabel(
            self, text=get_text("target_languages")
        )
        self.target_lang_label.grid(row=1, column=0, sticky="w", padx=5, pady=5)
        
        # ... å…¶ä»–æ§ä»¶
        
        # åŒè¯­æ¨¡å¼
        self.bilingual_var = ctk.BooleanVar(value=False)
        self.bilingual_switch = ctk.CTkSwitch(
            self,
            text=get_text("bilingual_mode"),
            variable=self.bilingual_var,
            command=self._on_change
        )
        self.bilingual_switch.grid(row=3, column=0, columnspan=2, sticky="w", padx=5, pady=5)
        
        # ç¿»è¯‘ç­–ç•¥
        self.strategy_label = ctk.CTkLabel(
            self, text=get_text("translation_strategy")
        )
        self.strategy_label.grid(row=4, column=0, sticky="w", padx=5, pady=5)
        
        self.strategy_combo = ctk.CTkComboBox(
            self,
            values=[
                get_text("strategy_ai_first"),
                get_text("strategy_official_first"),
                get_text("strategy_official_only"),
            ],
            command=self._on_change
        )
        self.strategy_combo.grid(row=4, column=1, sticky="ew", padx=5, pady=5)
    
    def _get_language_options(self) -> List[str]:
        """è·å–è¯­è¨€é€‰é¡¹åˆ—è¡¨"""
        return [
            "auto", "en", "zh-CN", "zh-TW", "ja", "ko",
            "de", "fr", "es", "pt", "ru", "it"
        ]
    
    def _on_change(self, *args):
        """é…ç½®å˜æ›´å›è°ƒ"""
        if self.on_config_changed:
            self.on_config_changed(self.get_config())
    
    def get_config(self) -> dict:
        """è·å–å½“å‰é…ç½®"""
        return {
            "source_language": self.source_lang_combo.get(),
            "target_languages": self._get_selected_targets(),
            "summary_language": self.summary_lang_combo.get(),
            "bilingual_mode": self.bilingual_var.get(),
            "translation_strategy": self._get_strategy_value(),
        }
    
    def set_config(self, config: dict):
        """è®¾ç½®é…ç½®"""
        if "source_language" in config:
            self.source_lang_combo.set(config["source_language"])
        if "bilingual_mode" in config:
            self.bilingual_var.set(config["bilingual_mode"])
        # ... å…¶ä»–è®¾ç½®
    
    def _get_selected_targets(self) -> List[str]:
        """è·å–é€‰ä¸­çš„ç›®æ ‡è¯­è¨€"""
        # å®ç°å¤šé€‰é€»è¾‘
        pass
    
    def _get_strategy_value(self) -> str:
        """è·å–ç¿»è¯‘ç­–ç•¥å€¼"""
        text = self.strategy_combo.get()
        if text == get_text("strategy_ai_first"):
            return "AI_FIRST"
        elif text == get_text("strategy_official_first"):
            return "OFFICIAL_FIRST"
        else:
            return "OFFICIAL_ONLY"
```

### 2.4 é¡µé¢ä½¿ç”¨ç¤ºä¾‹

```python
# ui/pages/url_list_page.py (æ”¹é€ å)

from ui.components.language_config_section import LanguageConfigSection

class URLListPage(ctk.CTkFrame):
    def __init__(self, parent, **kwargs):
        super().__init__(parent, **kwargs)
        self._create_widgets()
    
    def _create_widgets(self):
        # URL è¾“å…¥åŒºåŸŸ (ä¿æŒä¸å˜)
        self.url_input_section = self._create_url_input_section()
        
        # è¯­è¨€é…ç½®åŒºåŸŸ (ä½¿ç”¨å…¬å…±ç»„ä»¶)
        self.language_config = LanguageConfigSection(
            self,
            on_config_changed=self._on_language_config_changed
        )
        self.language_config.pack(fill="x", padx=10, pady=10)
        
        # è¿è¡ŒæŒ‰é’®åŒºåŸŸ (ä¿æŒä¸å˜)
        self.run_section = self._create_run_section()
    
    def _on_language_config_changed(self, config: dict):
        """è¯­è¨€é…ç½®å˜æ›´å¤„ç†"""
        # æ›´æ–°å†…éƒ¨çŠ¶æ€
        self.current_language_config = config
    
    def get_full_config(self) -> dict:
        """è·å–å®Œæ•´é…ç½®"""
        return {
            "urls": self._get_urls(),
            **self.language_config.get_config(),
        }
```

### 2.5 æ‰§è¡Œæ­¥éª¤

1. **åˆ›å»ºç»„ä»¶ç›®å½•**
   ```bash
   mkdir -p ui/components
   touch ui/components/__init__.py
   ```

2. **åˆ›å»º language_config_section.py**
   - ä» `url_list_page.py` ä¸­æå–è¯­è¨€é…ç½®ç›¸å…³ä»£ç 
   - å°è£…ä¸ºç‹¬ç«‹ç»„ä»¶

3. **æ”¹é€  url_list_page.py**
   - åˆ é™¤é‡å¤çš„è¯­è¨€é…ç½®ä»£ç 
   - å¼•å…¥ `LanguageConfigSection` ç»„ä»¶

4. **æ”¹é€  channel_page.py**
   - åŒæ ·å¼•å…¥ `LanguageConfigSection` ç»„ä»¶

5. **æµ‹è¯•ä¸¤ä¸ªé¡µé¢åŠŸèƒ½æ˜¯å¦æ­£å¸¸**

---

## ä»»åŠ¡3: language_strategy ç»Ÿä¸€

### 3.1 é—®é¢˜åˆ†æ

`core/downloader.py` å’Œ `core/translator.py` ä¸­æœ‰é‡å¤çš„è¯­è¨€å¤„ç†é€»è¾‘ï¼š

| é‡å¤ä»£ç  | downloader.py | translator.py |
|---------|--------------|---------------|
| `lang_matches()` å‡½æ•° | æœ‰ | æœ‰ (å®Œå…¨ç›¸åŒ) |
| `COMMON_LANGUAGES` åˆ—è¡¨ | æœ‰ | æœ‰ (å®Œå…¨ç›¸åŒ) |
| æºè¯­è¨€é€‰æ‹©ç®—æ³• | æœ‰ | æœ‰ (ç±»ä¼¼) |

### 3.2 ç›®æ ‡æ¶æ„

```
æ”¹é€ å‰:
â”œâ”€â”€ downloader.py  â†’ ~900è¡Œ (åŒ…å«è¯­è¨€é€»è¾‘)
â”œâ”€â”€ translator.py  â†’ ~770è¡Œ (åŒ…å«è¯­è¨€é€»è¾‘ï¼Œé‡å¤!)
æ€»è®¡: ~1,670è¡Œ

æ”¹é€ å:
â”œâ”€â”€ language_strategy.py â†’ ~150è¡Œ (å…¬å…±è¯­è¨€é€»è¾‘)
â”œâ”€â”€ downloader.py        â†’ ~750è¡Œ (ä½¿ç”¨å…¬å…±æ¨¡å—)
â”œâ”€â”€ translator.py        â†’ ~620è¡Œ (ä½¿ç”¨å…¬å…±æ¨¡å—)
æ€»è®¡: ~1,520è¡Œ
```

### 3.3 æ–°æ¨¡å—è®¾è®¡

```python
# core/language_strategy.py

"""
è¯­è¨€ç­–ç•¥æ¨¡å—
ç»Ÿä¸€å¤„ç†è¯­è¨€ä»£ç åŒ¹é…ã€æºè¯­è¨€é€‰æ‹©ç­‰é€»è¾‘
"""

from typing import Optional, List, Dict
from pathlib import Path


# å¸¸è§è¯­è¨€åˆ—è¡¨ï¼ˆæŒ‰ç¿»è¯‘è´¨é‡ä¼˜å…ˆçº§æ’åºï¼‰
COMMON_LANGUAGES = [
    "en", "en-US",
    "de", "de-DE",
    "ja", "ja-JP",
    "es", "es-ES",
    "fr", "fr-FR",
    "pt", "pt-PT",
    "ru", "ru-RU",
    "ko", "ko-KR",
]


def lang_matches(lang1: str, lang2: str) -> bool:
    """æ£€æŸ¥ä¸¤ä¸ªè¯­è¨€ä»£ç æ˜¯å¦åŒ¹é…
    
    ç‰¹æ®Šå¤„ç†:
    - zh-CN å’Œ zh-TW ä¸äº’ç›¸åŒ¹é…ï¼ˆéœ€è¦ç²¾ç¡®åŒ¹é…ï¼‰
    - å…¶ä»–è¯­è¨€ä½¿ç”¨ä¸»è¯­è¨€ä»£ç åŒ¹é…ï¼ˆå¦‚ en-US åŒ¹é… enï¼‰
    
    Args:
        lang1: ç¬¬ä¸€ä¸ªè¯­è¨€ä»£ç 
        lang2: ç¬¬äºŒä¸ªè¯­è¨€ä»£ç 
    
    Returns:
        æ˜¯å¦åŒ¹é…
    """
    if lang1 == lang2:
        return True
    
    # ç‰¹æ®Šå¤„ç†ï¼šzh-CN å’Œ zh-TW ä¸äº’ç›¸åŒ¹é…
    lang1_lower = lang1.lower()
    lang2_lower = lang2.lower()
    zh_cn_variants = ["zh-cn", "zh_cn"]
    zh_tw_variants = ["zh-tw", "zh_tw"]
    
    if (lang1_lower in zh_cn_variants and lang2_lower in zh_tw_variants) or \
       (lang1_lower in zh_tw_variants and lang2_lower in zh_cn_variants):
        return False
    
    # å…¶ä»–è¯­è¨€ï¼šæå–ä¸»è¯­è¨€ä»£ç è¿›è¡ŒåŒ¹é…
    main1 = lang1.split("-")[0].split("_")[0].lower()
    main2 = lang2.split("-")[0].split("_")[0].lower()
    return main1 == main2


def get_main_language_code(lang: str) -> str:
    """è·å–ä¸»è¯­è¨€ä»£ç 
    
    Args:
        lang: å®Œæ•´è¯­è¨€ä»£ç  (å¦‚ "en-US", "zh-CN")
    
    Returns:
        ä¸»è¯­è¨€ä»£ç  (å¦‚ "en", "zh")
    """
    return lang.split("-")[0].split("_")[0].lower()


def is_chinese_variant(lang: str) -> bool:
    """æ£€æŸ¥æ˜¯å¦æ˜¯ä¸­æ–‡å˜ä½“"""
    return get_main_language_code(lang) == "zh"


def find_best_source_language(
    available_languages: List[str],
    manual_languages: Optional[List[str]] = None,
    auto_languages: Optional[List[str]] = None,
    exclude_language: Optional[str] = None,
) -> Optional[str]:
    """åœ¨å¯ç”¨è¯­è¨€ä¸­æ‰¾åˆ°æœ€ä½³æºè¯­è¨€
    
    ä¼˜å…ˆçº§:
    1. å¸¸è§è¯­è¨€ä¸­çš„äººå·¥å­—å¹•
    2. å¸¸è§è¯­è¨€ä¸­çš„è‡ªåŠ¨å­—å¹•
    3. å…¶ä»–äººå·¥å­—å¹•
    4. å…¶ä»–è‡ªåŠ¨å­—å¹•
    
    Args:
        available_languages: å¯ç”¨çš„è¯­è¨€åˆ—è¡¨
        manual_languages: äººå·¥å­—å¹•è¯­è¨€åˆ—è¡¨
        auto_languages: è‡ªåŠ¨å­—å¹•è¯­è¨€åˆ—è¡¨
        exclude_language: è¦æ’é™¤çš„è¯­è¨€ï¼ˆé€šå¸¸æ˜¯ç›®æ ‡è¯­è¨€ï¼‰
    
    Returns:
        æœ€ä½³æºè¯­è¨€ä»£ç ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å› None
    """
    manual_languages = manual_languages or []
    auto_languages = auto_languages or []
    
    def should_exclude(lang: str) -> bool:
        if not exclude_language:
            return False
        return lang_matches(lang, exclude_language)
    
    # ä¼˜å…ˆçº§1: å¸¸è§è¯­è¨€ä¸­çš„äººå·¥å­—å¹•
    for common_lang in COMMON_LANGUAGES:
        for lang in manual_languages:
            if lang_matches(lang, common_lang) and not should_exclude(lang):
                if lang in available_languages:
                    return lang
    
    # ä¼˜å…ˆçº§2: å¸¸è§è¯­è¨€ä¸­çš„è‡ªåŠ¨å­—å¹•
    for common_lang in COMMON_LANGUAGES:
        for lang in auto_languages:
            if lang_matches(lang, common_lang) and not should_exclude(lang):
                if lang in available_languages:
                    return lang
    
    # ä¼˜å…ˆçº§3: å…¶ä»–äººå·¥å­—å¹•
    for lang in manual_languages:
        if not should_exclude(lang) and lang in available_languages:
            is_common = any(lang_matches(lang, c) for c in COMMON_LANGUAGES)
            if not is_common:
                return lang
    
    # ä¼˜å…ˆçº§4: å…¶ä»–è‡ªåŠ¨å­—å¹•
    for lang in auto_languages:
        if not should_exclude(lang) and lang in available_languages:
            is_common = any(lang_matches(lang, c) for c in COMMON_LANGUAGES)
            if not is_common:
                return lang
    
    return None


class LanguageSelector:
    """è¯­è¨€é€‰æ‹©å™¨
    
    å°è£…æºè¯­è¨€é€‰æ‹©çš„å®Œæ•´é€»è¾‘ï¼Œå¯è¢« downloader å’Œ translator å¤ç”¨
    """
    
    def __init__(
        self,
        manual_languages: Optional[List[str]] = None,
        auto_languages: Optional[List[str]] = None,
    ):
        self.manual_languages = manual_languages or []
        self.auto_languages = auto_languages or []
    
    def select_source_for_translation(
        self,
        official_translations: Dict[str, Path],
        original_path: Optional[Path],
        target_language: str,
    ) -> Optional[Path]:
        """é€‰æ‹©ç”¨äºç¿»è¯‘çš„æºå­—å¹•æ–‡ä»¶
        
        Args:
            official_translations: å·²ä¸‹è½½çš„å®˜æ–¹ç¿»è¯‘å­—å¹• {è¯­è¨€ä»£ç : è·¯å¾„}
            original_path: åŸå§‹å­—å¹•è·¯å¾„
            target_language: ç›®æ ‡è¯­è¨€
        
        Returns:
            æºå­—å¹•æ–‡ä»¶è·¯å¾„
        """
        available_languages = list(official_translations.keys())
        
        # ä½¿ç”¨é€šç”¨ç®—æ³•æ‰¾æœ€ä½³æºè¯­è¨€
        best_lang = find_best_source_language(
            available_languages=available_languages,
            manual_languages=self.manual_languages,
            auto_languages=self.auto_languages,
            exclude_language=target_language,
        )
        
        if best_lang:
            path = official_translations.get(best_lang)
            if path and path.exists():
                return path
        
        # å›é€€åˆ°åŸå§‹å­—å¹•
        if original_path and original_path.exists():
            return original_path
        
        return None
```

### 3.4 æ”¹é€  translator.py

```python
# æ”¹é€ å‰ (translator.py ä¸­çš„é‡å¤ä»£ç ):
# - COMMON_LANGUAGES åˆ—è¡¨ (åˆ é™¤)
# - lang_matches() å‡½æ•° (åˆ é™¤)
# - _select_source_subtitle() æ–¹æ³•ä¸­çš„å¤æ‚é€»è¾‘ (ç®€åŒ–)

# æ”¹é€ å:
from core.language_strategy import (
    lang_matches,
    COMMON_LANGUAGES,
    LanguageSelector,
)

class SubtitleTranslator:
    def __init__(self, llm, language_config):
        self.llm = llm
        self.language_config = language_config
        self._language_selector = None  # å»¶è¿Ÿåˆå§‹åŒ–
    
    def _select_source_subtitle(
        self,
        download_result: Dict,
        detection_result,
        target_language: str,
    ) -> Optional[Path]:
        """é€‰æ‹©æºå­—å¹•ï¼ˆç®€åŒ–ç‰ˆï¼Œä½¿ç”¨å…¬å…±æ¨¡å—ï¼‰"""
        # åˆå§‹åŒ–è¯­è¨€é€‰æ‹©å™¨
        if self._language_selector is None:
            self._language_selector = LanguageSelector(
                manual_languages=detection_result.manual_languages,
                auto_languages=detection_result.auto_languages,
            )
        
        return self._language_selector.select_source_for_translation(
            official_translations=download_result.get("official_translations", {}),
            original_path=download_result.get("original"),
            target_language=target_language,
        )
```

### 3.5 æ‰§è¡Œæ­¥éª¤

1. **åˆ›å»º language_strategy.py**
   ```bash
   touch core/language_strategy.py
   ```

2. **ä» translator.py æå–å…¬å…±ä»£ç **
   - `COMMON_LANGUAGES`
   - `lang_matches()`
   - æºè¯­è¨€é€‰æ‹©é€»è¾‘

3. **æ”¹é€  translator.py**
   - åˆ é™¤é‡å¤ä»£ç 
   - å¼•å…¥ `language_strategy` æ¨¡å—

4. **æ”¹é€  downloader.py**
   - åˆ é™¤é‡å¤ä»£ç 
   - å¼•å…¥ `language_strategy` æ¨¡å—

5. **æµ‹è¯•ç¿»è¯‘å’Œä¸‹è½½åŠŸèƒ½**

---

## ğŸ“‹ æ‰§è¡Œé¡ºåºå»ºè®®

```
Week 1: ä»»åŠ¡1 - ai_providers é‡æ„
â”œâ”€â”€ Day 1-2: è®¾è®¡å¹¶å®ç° BaseLLMClient
â”œâ”€â”€ Day 3: æ”¹é€  anthropic.py (éªŒè¯è®¾è®¡)
â”œâ”€â”€ Day 4: æ”¹é€  openai_compatible.py, gemini.py
â”œâ”€â”€ Day 5: æ”¹é€  local_model.py, google_translate.py
â””â”€â”€ Day 6-7: æµ‹è¯•å’Œä¿®å¤

Week 2: ä»»åŠ¡2 + ä»»åŠ¡3
â”œâ”€â”€ Day 1-2: ä»»åŠ¡2 - language_config_section UI ç»„ä»¶
â”œâ”€â”€ Day 3-4: ä»»åŠ¡3 - language_strategy ç»Ÿä¸€
â””â”€â”€ Day 5-7: é›†æˆæµ‹è¯•å’Œä¿®å¤
```

---

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **æ¯å®Œæˆä¸€ä¸ªå°æ”¹åŠ¨å°±æµ‹è¯•**
   - ä¸è¦ä¸€æ¬¡æ”¹å¤ªå¤š
   - ä¿æŒä»£ç å§‹ç»ˆå¯è¿è¡Œ

2. **ä¿ç•™å¤‡ä»½**
   ```bash
   git commit -m "Before refactoring" 
   # æˆ–æ‰‹åŠ¨å¤‡ä»½æ–‡ä»¶å¤¹
   ```

3. **ä¿æŒæ¥å£å…¼å®¹**
   - `factory.py` å’Œ `registry.py` ä¸éœ€è¦æ”¹
   - å¯¹å¤–çš„ç±»åå’Œæ–¹æ³•åä¿æŒä¸å˜

4. **æµ‹è¯•é‡ç‚¹**
   - AI è°ƒç”¨æ˜¯å¦æ­£å¸¸
   - é‡è¯•é€»è¾‘æ˜¯å¦ç”Ÿæ•ˆ
   - é”™è¯¯ä¿¡æ¯æ˜¯å¦æ­£ç¡®æ˜¾ç¤º
   - UI è¯­è¨€é…ç½®æ˜¯å¦æ­£å¸¸ä¿å­˜/è¯»å–

---

## ğŸ“Š é¢„æœŸæˆæœ

| æŒ‡æ ‡ | æ”¹é€ å‰ | æ”¹é€ å | å˜åŒ– |
|------|-------|-------|-----|
| æ€»ä»£ç é‡ | ~12,500è¡Œ | ~11,200è¡Œ | -1,300è¡Œ (10%) |
| ai_providers | ~1,160è¡Œ | ~540è¡Œ | -620è¡Œ |
| UI pages | ~1,550è¡Œ | ~1,350è¡Œ | -200è¡Œ |
| downloader + translator | ~1,670è¡Œ | ~1,520è¡Œ | -150è¡Œ |
| æ–°å¢ language_strategy | 0 | ~150è¡Œ | +150è¡Œ |
| æ–°å¢ UI components | 0 | ~200è¡Œ | +200è¡Œ |

**å‡€å‡å°‘: ~1,100-1,300 è¡Œä»£ç **
